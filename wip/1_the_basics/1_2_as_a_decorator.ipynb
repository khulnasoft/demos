{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "file: \"unify_existing_code/1_the_basics/1_2_as_a_decorator.ipynb\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1.2: As a Decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "`startai.unify`, `startai.trace_graph` and `startai.transpile` can all be called either as a function decorator or as a standalone function. All examples in the [Building Blocks]() section and all previous examples in [The Basics]() are called as standalone functions. In this section, we'll see how they can each be instead called as function decorators."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::: {#colab-button}\n",
    "[![Open in Colab]({{< var remote_badge.colab >}})](https://colab.research.google.com/github/khulnasoft/demos/blob/main/{{< meta file >}})\n",
    "[![GitHub]({{< var remote_badge.github >}})](https://github.com/khulnasoft/demos/blob/main/{{< meta file >}})\n",
    ":::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Unify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Firstly, let's create the dummy `numpy` arrays as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import numpy\n",
    "import numpy as np\n",
    "\n",
    "# create random numpy arrays for testing\n",
    "x = np.randon.uniform(size=10)\n",
    "mean = np.mean(x)\n",
    "std = np.std(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's assume that our target framework is `tensorflow`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "startai.set_backend(\"tensorflow\")\n",
    "\n",
    "x = tf.constant(x)\n",
    "mean = tf.constant(mean)\n",
    "std = tf.constant(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In the example below, the `startai.unify` function is called as a decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import startai\n",
    "import torch\n",
    "\n",
    "@startai.unify\n",
    "def normalize(x, mean, std):\n",
    "    return torch.div(torch.sub(x, mean), std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The function can still be called either *eagerly* or *lazily* when calling as a decorator. The example above is *lazy*, whereas the example below is *eager*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@startai.unify(args=(x, mean, std))\n",
    "def normalize(x, mean, std):\n",
    "    return torch.div(torch.sub(x, mean), std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The same is true for all other arguments, such as `from` for specifying the *source* framework locally. This argument can be passed when `startai.unify` is used as a decorator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In the example below, the `startai.trace_graph` function is also called as a decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@startai.trace_graph\n",
    "@startai.unify\n",
    "def normalize(x, mean, std):\n",
    "    return torch.div(torch.sub(x, mean), std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Likewise, the function can still be called either *eagerly* or *lazily* when calling as a decorator. The example above is *lazy*, whereas the example below is *eager*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@startai.trace_graph(args=(x, mean, std))\n",
    "@startai.unify\n",
    "def normalize(x, mean, std):\n",
    "    return torch.div(torch.sub(x, mean), std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The same is true for all other arguments, such as `to` for specifying the *target* framework locally. This argument can be passed when `startai.trace_graph` is used as a decorator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Transpile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In the example below, the `startai.transpile` function is called as a decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "@startai.transpile\n",
    "def normalize(x, mean, std):\n",
    "    return torch.div(torch.sub(x, mean), std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The function can still be called either *eagerly* or *lazily* when calling as a decorator. The example above is *lazy*, whereas the example below is *eager*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@startai.transpile(args=(x, mean, std))\n",
    "def normalize(x, mean, std):\n",
    "    return torch.div(torch.sub(x, mean), std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The same is true for all other arguments, such as `from` for specifying the *source* framework locally, and `to` for specifying the *target* framework locally. These arguments can be passed when `startai.transpile` is used as a decorator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Round Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "That's it, you now know how `startai.unify`, `startai.trace_graph` and `startai.transpile` can all be used as function decorators! However, there are several other important topics to master before you're ready to unify ML code like a pro ðŸ¥·. Next, we'll be exploring the difference between [dynamic vs static]() computation graphs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
