{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "file: \"unify_existing_code/0_building_blocks/0_2_transpile.ipynb\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 0.2: Transpile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this example, we transpile the original `normalize` function from `torch` to `jax` in one line of code. This is a common use case, where there is *one* target framework in mind."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::: {#colab-button}\n",
    "[![Open in Colab]({{< var remote_badge.colab >}})](https://colab.research.google.com/github/khulnasoft/demos/blob/main/{{< meta file >}})\n",
    "[![GitHub]({{< var remote_badge.github >}})](https://github.com/khulnasoft/demos/blob/main/{{< meta file >}})\n",
    ":::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Using what we learnt in the previous two notebooks for [Unify]() and [Compile](), the workflow for converting directly from `torch` to `jax` would be as follows, first unifying to `startai` code, and then compiling to the `jax` backend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import startai\n",
    "import torch\n",
    "startai.set_backend(\"jax\")\n",
    "\n",
    "def normalize(x, mean, std):\n",
    "    return torch.div(torch.sub(x, mean), std)\n",
    "\n",
    "normalize = startai.trace_graph(startai.unify(normalize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "`normalize` is now compiled to machine-code, specifically for `jax`, ready to be integrated into your wider `jax` project.\n",
    "\n",
    "This workflow is common, and so in order to avoid repeated calls to `startai.unify` followed by `startai.trace_graph`, there is another convenience function `startai.transpile`, which basically acts as a shorthand for this pair of function calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalize = startai.transpile(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Again, `normalize` is now compiled to machine-code, specifically for `jax`, ready to be integrated into your wider `jax` project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Round Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "That's it, you can now transpile code from one framework to another with one line of code! That concludes the collection of notebooks on the \"Building Blocks\". However, there are still many other important topics to master before you're ready to unify ML code like a pro ðŸ¥·. In the next collection of notebooks \"The Basics\", we'll be learning about the various different ways that `startai.unify`, `startai.trace_graph` and `startai.transpile` can be called, and what implications each of these have."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
